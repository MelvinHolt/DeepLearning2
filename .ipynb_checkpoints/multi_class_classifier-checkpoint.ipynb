{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import Input, Dense, Conv2D, MaxPooling2D, Flatten, Activation, Dropout, Lambda\n",
    "from keras.optimizers import Adadelta, Adam\n",
    "from keras.callbacks import ReduceLROnPlateau, ModelCheckpoint\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import tensorflow as tf\n",
    "\n",
    "from keras.applications.resnet50 import ResNet50\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'val_labeled' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-5aaf015b2efb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mval_labeled\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'label'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalue_counts\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'val_labeled' is not defined"
     ]
    }
   ],
   "source": [
    "val_labeled['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "373/634"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "USE_RESNET = False\n",
    "\n",
    "INPUT_SHAPE = (100, 100, 3)\n",
    "TARGET_SIZE = (100, 100)\n",
    "NUM_CLASSES =  101\n",
    "LEARNING_RATE = 0.001\n",
    "PATIENCE = 3\n",
    "VERBOSE = 1\n",
    "LEARNING_RATE_REDUCTION_FACTOR = 0.5\n",
    "MIN_LEARNING_RATE = 0.00001\n",
    "\n",
    "EPOCHS = 100\n",
    "BATCH_SIZE = 50\n",
    "\n",
    "MODEL_NAME = 'category_model'\n",
    "OUTPUT_DIR = 'output'\n",
    "SEED = 42\n",
    "\n",
    "MODEL_OUT_DIR = os.path.join(OUTPUT_DIR, MODEL_NAME)\n",
    "                            \n",
    "if not os.path.exists(MODEL_OUT_DIR):\n",
    "    os.makedirs(MODEL_OUT_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labeled = pd.read_csv('data/train_labeled.csv')\n",
    "test_labeled = pd.read_csv('data/test_labeled.csv')\n",
    "val_labeled = pd.read_csv('data/val_labeled.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_process(x):\n",
    "    import tensorflow as tf\n",
    "    hsv = tf.image.rgb_to_hsv(x)\n",
    "    gray = tf.image.rgb_to_grayscale(x)\n",
    "    rez = tf.concat([hsv, gray], axis=-1)\n",
    "    return rez\n",
    "\n",
    "def network(input_shape, num_classes):\n",
    "    img_input = Input(shape=input_shape, name='data')\n",
    "    x = Lambda(image_process)(img_input)\n",
    "    x = Conv2D(16, (5, 5), strides=(1, 1), padding='same', name='conv1')(x)\n",
    "    x = Activation('relu', name='conv1_relu')(x)\n",
    "    x = MaxPooling2D((2, 2), strides=(2, 2), padding='valid', name='pool1')(x)\n",
    "    x = Conv2D(32, (5, 5), strides=(1, 1), padding='same', name='conv2')(x)\n",
    "    x = Activation('relu', name='conv2_relu')(x)\n",
    "    x = MaxPooling2D((2, 2), strides=(2, 2), padding='valid', name='pool2')(x)\n",
    "    x = Conv2D(64, (5, 5), strides=(1, 1), padding='same', name='conv3')(x)\n",
    "    x = Activation('relu', name='conv3_relu')(x)\n",
    "    x = MaxPooling2D((2, 2), strides=(2, 2), padding='valid', name='pool3')(x)\n",
    "    x = Conv2D(128, (5, 5), strides=(1, 1), padding='same', name='conv4')(x)\n",
    "    x = Activation('relu', name='conv4_relu')(x)\n",
    "    x = MaxPooling2D((2, 2), strides=(2, 2), padding='valid', name='pool4')(x)\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(512, activation='relu', name='fcl1')(x)\n",
    "    x = Dropout(0.2)(x)\n",
    "    x = Dense(128, activation='relu', name='fcl2')(x)\n",
    "    x = Dropout(0.2)(x)\n",
    "    out = Dense(num_classes, activation='softmax', name='predictions')(x)\n",
    "    rez = Model(inputs=img_input, outputs=out)\n",
    "    return rez\n",
    "\n",
    "def resnet(input_shape, num_classes):\n",
    "    resnet = ResNet50(weights='imagenet',\n",
    "                       input_shape=input_shape,\n",
    "                   include_top=False)\n",
    "    image = resnet.get_layer(index=0).output\n",
    "    output = resnet.get_layer(index=-1).output\n",
    "    output = Flatten()(output)\n",
    "#     output = Dense(num_classes, activation='sigmoid', name='predictions')(output)\n",
    "    for layer in resnet.layers:\n",
    "        layer.trainable = False\n",
    "        \n",
    "    resnet = Model(inputs = image, outputs = output)\n",
    "    model = Sequential()\n",
    "    model.add(resnet)\n",
    "    model.add(Dense(512, activation='relu', input_dim=input_shape))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Dense(512, activation='relu'))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Dense(num_classes, activation='sigmoid', name='predictions'))\n",
    "    model.summary();\n",
    "    \n",
    "    return model\n",
    "    \n",
    "if USE_RESNET:\n",
    "    model = resnet(input_shape=INPUT_SHAPE, num_classes=NUM_CLASSES)\n",
    "else:\n",
    "    model = network(input_shape=INPUT_SHAPE, num_classes=NUM_CLASSES)\n",
    "# model = resnet(input_shape=INPUT_SHAPE, num_classes=NUM_CLASSES)\n",
    "# model = resnet(input_shape=INPUT_SHAPE, num_classes=NUM_CLASSES)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the Data Generators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "        width_shift_range=0.0,\n",
    "        height_shift_range=0.0,\n",
    "        zoom_range=0.0,\n",
    "        horizontal_flip=True,\n",
    "        vertical_flip=True,  # randomly flip images\n",
    "        rescale=1./255.\n",
    ")\n",
    "\n",
    "\n",
    "train_generator = datagen.flow_from_dataframe(\n",
    "    dataframe=train_labeled,\n",
    "    directory=\"./Recipes5k/images/\",\n",
    "    x_col=\"url\",\n",
    "    y_col=\"category\",\n",
    "    subset=\"training\",\n",
    "    batch_size=32,\n",
    "    seed=SEED,\n",
    "    shuffle=True,\n",
    "    class_mode=\"categorical\",\n",
    "#     classes=['Vegetarian', 'Non-Vegetarian'],\n",
    "#     classes={'Non-Vegetarian':1, 'Vegetarian':0},\n",
    "    target_size=TARGET_SIZE\n",
    ")\n",
    "labels = train_generator.class_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_datagen = ImageDataGenerator(\n",
    "    rescale=1./255.\n",
    ")\n",
    "\n",
    "\n",
    "test_generator = test_datagen.flow_from_dataframe(\n",
    "    dataframe=test_labeled,\n",
    "    directory=\"./Recipes5k/images/\",\n",
    "    x_col=\"url\",\n",
    "    y_col=\"category\",\n",
    "    batch_size=1,\n",
    "    seed=SEED,\n",
    "    shuffle=False,\n",
    "    class_mode=\"categorical\",\n",
    "    target_size=TARGET_SIZE,\n",
    "    classes = labels\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_datagen = ImageDataGenerator(\n",
    "        width_shift_range=0.0,\n",
    "        height_shift_range=0.0,\n",
    "        zoom_range=0.0,\n",
    "        horizontal_flip=True,\n",
    "        vertical_flip=True,  # randomly flip images\n",
    "        rescale=1./255.\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_generator = val_datagen.flow_from_dataframe(\n",
    "    dataframe=val_labeled,\n",
    "    directory=\"./Recipes5k/images/\",\n",
    "    x_col=\"url\",\n",
    "    y_col=\"category\",\n",
    "    batch_size=32,\n",
    "    seed=SEED,\n",
    "    shuffle=False,\n",
    "    class_mode=\"categorical\",\n",
    "    target_size=TARGET_SIZE,\n",
    "    classes = labels\n",
    ")\n",
    "# val_generator.class_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras.backend as K\n",
    "\n",
    "def recall_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    return recall\n",
    "\n",
    "def precision_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    return precision\n",
    "\n",
    "def f1_m(y_true, y_pred):\n",
    "    precision = precision_m(y_true, y_pred)\n",
    "    recall = recall_m(y_true, y_pred)\n",
    "    return 2*((precision*recall)/(precision+recall+K.epsilon()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def focal_loss(y_true, y_pred):\n",
    "    gamma = 2.0\n",
    "    alpha = 0.25\n",
    "    pt_1 = tf.where(tf.equal(y_true, 1), y_pred, tf.ones_like(y_pred))\n",
    "    pt_0 = tf.where(tf.equal(y_true, 0), y_pred, tf.zeros_like(y_pred))\n",
    "    return -K.sum(alpha * K.pow(1. - pt_1, gamma) * K.log(pt_1))-K.sum((1-alpha) * K.pow( pt_0, gamma) * K.log(1. - pt_0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import class_weight\n",
    "class_weights = class_weight.compute_class_weight('balanced',\n",
    "                                                 np.unique(train_labeled['category']),\n",
    "                                                 train_labeled['category'])\n",
    "class_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = Adam(lr = LEARNING_RATE)\n",
    "model.compile(optimizer = opt, loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "learning_rate_reduction = ReduceLROnPlateau(\n",
    "                    monitor='val_loss', \n",
    "                    patience=PATIENCE, verbose=VERBOSE, \n",
    "                    factor=LEARNING_RATE_REDUCTION_FACTOR, \n",
    "                    min_lr=MIN_LEARNING_RATE\n",
    ")\n",
    "save_model = ModelCheckpoint(filepath=MODEL_OUT_DIR + \"/model.h5\", monitor='val_accuracy', verbose=VERBOSE, \n",
    "                             save_best_only=True, save_weights_only=False, mode='max', period=1)\n",
    "\n",
    "\n",
    "history = model.fit_generator(generator=train_generator,\n",
    "                                  epochs=EPOCHS,\n",
    "                                  steps_per_epoch=(train_generator.n // BATCH_SIZE) + 1, \n",
    "                                  verbose=VERBOSE,\n",
    "                                  validation_data=val_generator,\n",
    "                                  validation_steps=(val_generator.n // BATCH_SIZE) + 1,\n",
    "                                  callbacks=[learning_rate_reduction, save_model]\n",
    "                             )\n",
    "# weights = model.load_weights(MODEL_OUT_DIR + \"/model.h5\")\n",
    "# weights\n",
    "# validation_data=validation_gen,\n",
    "#                                   validation_steps=(val_generator.n // BATCH_SIZE) + 1,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kaas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_model_history(model_history, out_path=\"\"):\n",
    "    fig, axs = plt.subplots(1, 2, figsize=(15, 5))\n",
    "    # summarize history for accuracy\n",
    "    axs[0].plot(range(1, len(model_history.history['accuracy']) + 1), model_history.history['accuracy'])\n",
    "    axs[0].plot(range(1, len(model_history.history['val_accuracy']) + 1), model_history.history['val_accuracy'])\n",
    "    axs[0].set_title('Model Accuracy')\n",
    "    axs[0].set_ylabel('Accuracy')\n",
    "    axs[0].set_xlabel('Epoch')\n",
    "    axs[0].legend(['train', 'val'], loc='best')\n",
    "    # summarize history for loss\n",
    "    axs[1].plot(range(1, len(model_history.history['loss']) + 1), model_history.history['loss'])\n",
    "    axs[1].plot(range(1, len(model_history.history['val_loss']) + 1), model_history.history['val_loss'])\n",
    "    axs[1].set_title('Model Loss')\n",
    "    axs[1].set_ylabel('Loss')\n",
    "    axs[1].set_xlabel('Epoch')\n",
    "    axs[1].legend(['train', 'val'], loc='best')\n",
    "    # save the graph in a file called \"acc_loss.png\" to be available for later; the model_name is provided when creating and training a model\n",
    "    if out_path:\n",
    "        plt.savefig(out_path + \"/acc_loss.png\")\n",
    "    plt.show()\n",
    "\n",
    "def plot_confusion_matrix(y_true, y_pred, classes, out_path=\"\"):\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    df_cm = pd.DataFrame(cm, index=[i for i in classes], columns=[i for i in classes])\n",
    "    plt.figure(figsize=(40, 40))\n",
    "    ax = sn.heatmap(df_cm, annot=True, square=True, fmt=\"d\", linewidths=.2, cbar_kws={\"shrink\": 0.8})\n",
    "    if out_path:\n",
    "        plt.savefig(out_path + \"/confusion_matrix.png\")  # as in the plot_model_history, the matrix is saved in a file called \"model_name_confusion_matrix.png\"\n",
    "    return ax    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.load_weights(MODEL_OUT_DIR + \"/model.h5\")\n",
    "\n",
    "val_generator.reset()\n",
    "test_generator.reset()\n",
    "# loss_v, accuracy_v = model.evaluate_generator(val_generator, steps=(val_generator.n // BATCH_SIZE) + 1, verbose=VERBOSE)\n",
    "# loss, accuracy = model.evaluate_generator(test_generator, steps=(test_generator.n // BATCH_SIZE) + 1, verbose=VERBOSE)\n",
    "# print(\"Validation: accuracy = %f  ;  loss_v = %f\" % (accuracy_v, loss_v))\n",
    "# print(\"Test: accuracy = %f  ;  loss_v = %f\" % (accuracy, loss))\n",
    "\n",
    "# plot_model_history(history, out_path=MODEL_OUT_DIR)\n",
    "test_generator.reset()\n",
    "y_pred = model.predict_generator(test_generator, steps=test_generator.n, verbose=VERBOSE)\n",
    "# test = np.where(y_pred > 0.50, 1, 0)\n",
    "y_true = test_generator.classes\n",
    "# plot_confusion_matrix(y_true, y_pred.argmax(axis=-1), None, out_path=MODEL_OUT_DIR)\n",
    "# class_report = classification_report(y_true, y_pred.argmax(axis=-1), target_names=labels)\n",
    "\n",
    "# with open(MODEL_OUT_DIR + \"/classification_report.txt\", \"w\") as text_file:\n",
    "#     text_file.write(\"%s\" % class_report)\n",
    "# print(class_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred.argmax(axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_labels = pd.read_csv('data/category_not_vegetarian.csv', index_col='category')\n",
    "category_labels.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "labels = {value:key for key, value in test_generator.class_indices.items()}\n",
    "y_pred_labels = np.vectorize(labels.get)(y_pred.argmax(axis=-1))\n",
    "y_pred_binary = [category_labels.loc[pred]['vegetarian'] for pred in y_pred_labels]\n",
    "\n",
    "y_true_labels = np.vectorize(labels.get)(y_true)\n",
    "y_true_binary = [category_labels.loc[pred]['vegetarian'] for pred in y_true_labels]\n",
    "\n",
    "\n",
    "accuracy_score(y_true_binary, y_pred_binary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(y_true_binary, y_pred_binary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(y_true_binary, y_pred_binary, None, out_path=MODEL_OUT_DIR)\n",
    "class_report = classification_report(y_true_binary, y_pred_binary, target_names=labels)\n",
    "\n",
    "with open(MODEL_OUT_DIR + \"/classification_report.txt\", \"w\") as text_file:\n",
    "    text_file.write(\"%s\" % class_report)\n",
    "print(class_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(y_true, y_pred.argmax(axis=-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# confusion_matrix(y_true,y_pred.argmax(axis=-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(y_true)[0].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred[y_pred>0.5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = np.where(y_pred > 0.50, 1, 0)\n",
    "test;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_labeled['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "492/783"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred[y_pred < 0.55]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict_generator(test_generator, verbose=VERBOSE)\n",
    "y_pred.argmax(axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kaas = y_pred > 0.5\n",
    "kaas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_class_indices = np.argmax(y_pred, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = np.argmax(y_pred, axis=1)\n",
    "\n",
    "labels = (train_generator.class_indices)\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_model_history(model_history, out_path=\"\"):\n",
    "    fig, axs = plt.subplots(1, 2, figsize=(15, 5))\n",
    "    # summarize history for accuracy\n",
    "    axs[0].plot(range(1, len(model_history.history['accuracy']) + 1), model_history.history['accuracy'])\n",
    "    axs[0].plot(range(1, len(model_history.history['val_accuracy']) + 1), model_history.history['val_accuracy'])\n",
    "    axs[0].set_title('Model Accuracy')\n",
    "    axs[0].set_ylabel('Accuracy')\n",
    "    axs[0].set_xlabel('Epoch')\n",
    "    axs[0].legend(['train', 'val'], loc='best')\n",
    "    # summarize history for loss\n",
    "    axs[1].plot(range(1, len(model_history.history['loss']) + 1), model_history.history['loss'])\n",
    "    axs[1].plot(range(1, len(model_history.history['val_loss']) + 1), model_history.history['val_loss'])\n",
    "    axs[1].set_title('Model Loss')\n",
    "    axs[1].set_ylabel('Loss')\n",
    "    axs[1].set_xlabel('Epoch')\n",
    "    axs[1].legend(['train', 'val'], loc='best')\n",
    "    # save the graph in a file called \"acc_loss.png\" to be available for later; the model_name is provided when creating and training a model\n",
    "    if out_path:\n",
    "        plt.savefig(out_path + \"/acc_loss.png\")\n",
    "    plt.show()\n",
    "\n",
    "def plot_confusion_matrix(y_true, y_pred, classes, out_path=\"\"):\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    df_cm = pd.DataFrame(cm, index=[i for i in classes], columns=[i for i in classes])\n",
    "    plt.figure(figsize=(40, 40))\n",
    "    ax = sn.heatmap(df_cm, annot=True, square=True, fmt=\"d\", linewidths=.2, cbar_kws={\"shrink\": 0.8})\n",
    "    if out_path:\n",
    "        plt.savefig(out_path + \"/confusion_matrix.png\")  # as in the plot_model_history, the matrix is saved in a file called \"model_name_confusion_matrix.png\"\n",
    "    return ax    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = test_generator.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict_generator(test_generator, steps=test_generator.n, verbose=VERBOSE)\n",
    "len(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_labeled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
